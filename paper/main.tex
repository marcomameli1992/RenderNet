\section{Introduction}
\label{sec:introduction}
Computer graphics (CG) has revolutionized numerous fields, enabling the creation of visually stunning digital content~\cite{mamurova2023role}.
In this dynamic and constantly evolving field, achieving real-time rendering with uncompromising visual quality remains an elusive challenge. The demand for high-fidelity images in real-time applications, such as video games, simulations, and virtual reality experiences, has led to a pressing need for innovative solutions that address the time-quality trade-off. Achieving high visual quality in CG remains a complex task, particularly when time is of the essence~\cite{agoston2005computer}. One critical aspect of CG lies in rendering a 3D scene into an image, a process that demands substantial computing resources and time~\cite{peresunko2021models}. The rendering operation plays a pivotal role within the simulation context, and it encompasses two main techniques: real-time rendering and path-tracing rendering. Real-time rendering offers rapid image generation but compromises on the intricate details that contribute to visual realism. In contrast, path-tracing rendering produces images of exceptional quality, considering shadows, lighting, and material intricacies, but at the cost of substantial time investment. Bridging the gap between real-time and path-tracing rendering is a longstanding challenge that has profound implications across various domains~\cite{wu2020analytic}.

In response to these challenges, Deep learning has emerged as a transformative force in the realm of real-time rendering, revolutionizing the way we approach the age-old challenge of achieving high visual quality with limited computational resources~\cite{xiao2020neural}. Traditionally, real-time rendering has grappled with the trade-off between speed and visual fidelity, often sacrificing the latter for interactive performance. However, the advent of deep learning techniques, such as Generative Adversarial Networks (GANs)~\cite{goodfellow2020generative} and convolutional neural networks (CNNs), has opened up new possibilities for accelerating image generation without compromising on realism. By training encoder-decoder architectures on huge datasets of rendered images, deep learning models can now approximate the intricate details of scenes and produce visually compelling results in real-time~\cite{shi2021towards}. From video games to virtual reality experiences, the integration of deep learning in real-time rendering has not only elevated visual quality but also unlocked innovative approaches to bridging the gap between real-time and offline rendering techniques. By harnessing the power of convolutional networks and leveraging images generated by real-time engines, it becomes possible to generate output images that closely resemble those produced by path-tracing engines. This convergence of deep learning and real-time rendering has the potential to revolutionize the field, opening up new possibilities for accelerated image generation in CG~\cite{shi2021towards}.

Considering this context, in this paper it is introduced RenderGAN, a groundbreaking deep learning-based solution tailored to tackle the time-quality trade-off in real-time computer graphics. By leveraging G-Buffers and information from a real-time rendering engine, RenderGAN generates output images with extraordinary visual fidelity. Its encoder-decoder architecture, trained using the GAN framework with perceptual loss, enhances the realism of the generated images. Through rigorous quantitative comparisons with path-tracing engine results, RenderGAN achieves an impressive Universal Image Quality Index (UIQI) value of 0.898. Additionally, visualizations demonstrate the striking resemblance between RenderGAN's rendered images and those produced by path-tracing engines. What sets RenderGAN apart is its commitment to openness, encouraging collaboration, innovation, and accessibility within the computer graphics community. Unlike proprietary alternatives, RenderGAN fosters collective efforts to advance real-time computer graphics and rendering techniques, benefiting diverse applications and industries. By seamlessly merging deep learning and real-time rendering, RenderGAN opens up new avenues for accelerated image generation, bridging the gap between real-time and path-tracing rendering. The remarkable reduction in rendering time, without compromising visual quality, promises to revolutionize real-time computer graphics, propelling innovation in this dynamic and ever-evolving field. RenderGAN's open-source nature empowers researchers and practitioners to explore the forefront of accelerated image generation, driving the future of real-time rendering and fostering a collaborative, forward-thinking community.

The main contributions of this paper are as follows: i) the design of RenderGAN, a novel deep learning-based solution that addresses the time-quality trade-off in real-time computer graphics. RenderGAN uses G-Buffers and information from a real-time rendering engine as inputs to generate output images with remarkable visual fidelity; ii) presenting an innovative encoder-decoder architecture for image generation, trained using the Generative Adversarial Network (GAN) framework with perceptual loss, it enhances the realism of the generated images, achieving high-quality outputs; iii) the demonstration of RenderGAN effectiveness  through a rigorous quantitative comparison with images produced by a path-tracing engine. This evaluation showcases RenderGAN's impressive performance, achieving a remarkable Universal Image Quality Index (UIQI) value of 0.898; iv) distinguishing itself as an open-source solution, RenderGAN fosters collaboration, innovation, and accessibility within the computer graphics community. Unlike proprietary alternatives, RenderGAN promotes collective efforts to advance real-time computer graphics and rendering techniques.

The paper is organised as follows: in Section~\ref{sec:sota}, we embark on a comprehensive exploration of the state-of-the-art techniques meticulously analysing the advancements in computer graphics and rendering methods. Following this analysis, in Section~\ref{sec:methods}, we introduce our innovative solution, RenderGAN, designed to tackle the time-quality trade-off in real-time computer graphics. We present the methodology employed and the details of our encoder-decoder architecture for image generation using deep learning. The remarkable results achieved by RenderGAN are thoroughly discussed and quantitatively evaluated in Section~\ref{sec:rendering_results}, highlighting the compelling Universal Image Quality Index (UIQI) value attained. Additionally, visualizations of the rendered images produced by RenderGAN are provided, visually showcasing its effectiveness. Finally, in Section~\ref{sec:conclusion}, we conclude the paper by summarizing the contributions and impact of our work, and outline future research directions to further advance the field of explainability in 3D point cloud analysis.


\section{Related Works}
\label{sec:sota}
In this section, we conduct a comprehensive review of the state-of-the-art techniques in two key areas: real-time rendering and image and video superresolution. We delve into the advancements and innovations within these domains, exploring how they have tackled the challenges of achieving high visual quality and real-time performance in computer graphics and image processing. Through this review, we aim to shed light on the latest methodologies and cutting-edge approaches that have significantly contributed to pushing the boundaries of real-time rendering and elevating the visual fidelity of images and videos through superresolution techniques.

\subsection{Real-Time Rendering}
One of the crucial challenges in real-time rendering is undersampling, where each rendered sample represents a single point in the scene. However, to achieve an antialiased image, it is necessary to compute multiple samples within a sensor's pixel area. This discrepancy becomes particularly problematic for highly detailed surfaces, as undersampling can result in jarring visual effects such as shimmering and flickering when surface features are reduced to subpixel size. To address this issue, various methods have been developed to mitigate the different sources of aliasing in undersampled images. We can categorize these methods into two groups: spatial-only antialiasing techniques, which utilize information from a single rendered image, and temporal antialiasing methods, which leverage temporal history from multiple rendered frames. By employing these approaches, real-time rendering can overcome undersampling challenges and achieve improved visual quality in dynamic scenes.

\subsubsection{Spatial Antialiasing.}
In real-time graphics, multisampling antialiasing (MSAA) is a classic technique that falls under the category of supersampling. With MSAA, the color of a polygon covered by a pixel is calculated only once, avoiding the need to compute multiple subpixel samples for the same polygon~\cite{akeley1993reality}. Another well-established method is texture filtering, wherein high-frequency details from surface textures are prefiltered using image pyramids~\cite{williams1983pyramidal}. During runtime, a suitable prefiltered region is selected based on the pixel's footprint projected onto the textured surface. Specialized methods can also address aliasing from other shading components, such as specular highlights or shadows~\cite{kaplanyan2016filtering},~\cite{reeves1987rendering}.

Most spatial antialiasing methods rely on image enhancement techniques from image processing. The fundamental idea is to identify image discontinuities and cleverly blur them to smooth out jagged edges. Morphological antialiasing (MLAA) attempts to estimate the pixel coverage of the original geometry by analyzing color discontinuities in the vicinity of pixels in the final image~\cite{reshetov2009morphological}. Fast approximate antialiasing (FXAA) tackles the undersampling problem by attenuating subpixel features, thereby enhancing perceived temporal stability. Subpixel morphological antialiasing (SMAA) combines MLAA with MSAA to further improve image quality. While these methods can produce satisfactory results for static images, the temporal variation between frames antialiased with these techniques may still exhibit visible flicker and other false pixel motion. As a result, real-time rendering faces ongoing challenges in achieving both spatial and temporal antialiasing with superior visual fidelity~\cite{jimenez2012smaa}.

\subsubsection{Temporal Antialiasing and Reconstruction.}
These techniques used temporal history, often stored in a temporally accumulated buffer, coupled with various forms of temporal rejection filtering. The primary distinction lies in the approach of high-quality temporal methods, such as amortized supersampling~\cite{yang2009amortized}, which involve reprojecting history from one frame to another to compensate for motion, similar to motion compensation in video compression. Temporal antialiasing (TAA)~\cite{karis2014high}, on the other hand, used an edge detection filter to suppress flickering through heavier temporal accumulation. Recently, TAA has also been employed for temporal upsampling (TAAU)~\cite{osman2021design},.

Deep-learned supersampling (DLSS) used temporal history and neural networks to enhance edges and perform upscaling~\cite{edelsten2019truly}. However, details, quality, and performance information for DLSS are not readily available in the public domain which provides comprehensive details and evaluations, accessible without the need for proprietary hardware or software.

Furthermore, a recent trend in reducing rendering costs involves applying reconstruction methods to sparsely ray-traced~\cite{schied2017spatiotemporal} and foveated images~\cite{patney2016towards}. In this context, machine learning methods have been explored for real-time low-sample-count reconstruction~\cite{chaitanya2017interactive} and foveated reconstruction~\cite{kaplanyan2019deepfovea}. These techniques employ temporally stable U-Net architectures to achieve stable reconstructed videos from noisy and/or sparse input frames, which relates to our task of interpolation for upsampling.

\subsection{Image and Video Superresolution}

\subsubsection{Single Image Superresolution.}
Single image superresolution (SISR) tackles the challenging task of restoring a high-resolution image from a degraded, low-resolution version. The groundbreaking SRCNN~\cite{dong2015image} started the use of a 3-layer convolutional neural network (CNN) for SISR, sparking a surge of deep neural network approaches that now set the standard for quality. Rather than directly mapping the high-resolution target image to the low-resolution input image, VDSR~\cite{kim2016accurate} adopts a clever approach of learning the residual between the two. SRResNet~\cite{ledig2017photo}, inspired by the residual network architecture~\cite{he2016deep}, addresses superresolution by leveraging residual blocks. EDSR~\cite{lim2017enhanced} elevates performance further by incorporating a greater number of modified residual blocks. For real-time performance, ESPCN~\cite{shi2016real} introduces a subpixel CNN that operates at low resolution. LapSRN~\cite{lai2017deep}, on the other hand, proposes a Laplacian pyramid network to progressively reconstruct sub-band residuals of high-resolution images. RDN~\cite{zhang2018residual} effectively combines residual and dense connections~\cite{huang2017densely} for hierarchical feature extraction. Taking it a step further, RCAN~\cite{zhang2018image} introduces a residual-in-residual structure, forming an impressively deep network with over 400 convolutional layers, and a channel attention mechanism to adaptively rescale channel-wise features, leading to state-of-the-art quality results. Some approaches~\cite{ge2018image},~\cite{ledig2017photo} rely on generative adversarial networks to optimize perceptual quality, although this often comes at the expense of limited reconstruction fidelity and temporal consistency.

\subsubsection{Video Superresolution.}
Video superresolution methods often leverage the temporal coherence present in neighboring frames to enhance the reconstruction beyond what can be achieved using single-image superresolution (SISR) methods.
Many of the existing methods in this domain rely on motion estimation between frames as a crucial element. VESPCN~\cite{caballero2017real} introduces a multi-resolution spatial transformer module, serving the dual purpose of joint motion compensation and video superresolution. SPMC-VSR~\cite{tao2017detail}, on the other hand, incorporates a subpixel motion compensation layer to merge multiple frames, revealing intricate image details. EDVR~\cite{wang2019edvr} takes a comprehensive approach, implementing a pyramid, cascading, and deformable alignment module, alongside a temporal and spatial attention module. In contrast, DUF~\cite{jo2018deep} proposes a unique deep neural network that generates dynamic upsampling filters based on the local spatio-temporal neighborhood of each pixel, effectively bypassing the need for explicit motion compensation.

Alternatively, another category of methods harnesses the power of recurrent neural networks (RNN), which naturally encourage temporally consistent outcomes. FRVSR~\cite{vemulapalli2020frame} introduces an RNN that warps the previously estimated frame, facilitating the subsequent frame's generation. RBPN~\cite{haris2019recurrent}, on the other hand, adopts a recurrent encoder-decoder architecture, combining features from single-image and multi-frame modules. While RNN methods promote temporal coherence, their results may lack spatial details due to the averaging nature of simple norm loss functions during training. In an attempt to address this limitation, TecoGAN~\cite{chu2020learning} enhances the training loss and introduces a temporally self-supervised adversarial learning algorithm, aiming to retain both temporal consistency and spatial details in the generated video sequences.

RenderGAN stands apart from the state-of-the-art approaches in real-time rendering and image superresolution due to its unique combination of deep learning and rendering techniques. While traditional real-time rendering engines, such as those employing real-time rendering and path-tracing rendering, trade off between speed and visual quality, RenderGAN introduces a novel encoder-decoder architecture for image generation that leverages deep learning through the Generative Adversarial Network (GAN) framework. Unlike some other approaches that solely focus on improving spatial resolution or applying temporal antialiasing, RenderGAN addresses the time-quality trade-off inherent in real-time rendering by efficiently generating high-quality images in a real-time context. By utilizing G-Buffers and information from a real-time rendering engine as inputs, RenderGAN achieves remarkable visual fidelity, surpassing the limitations of conventional real-time rendering engines. RenderGAN also stands out from traditional single-image superresolution methods by targeting the specific challenges of real-time rendering and addressing them through a deep learning-based solution. While single-image superresolution techniques typically enhance the resolution of a single image, RenderGAN goes beyond this scope to generate images in real-time while maintaining high visual quality. Furthermore, RenderGAN distinguishes itself by being an open-source solution, promoting collaboration, accessibility, and innovation within the computer graphics community. This openness contrasts with some existing proprietary methods, making RenderGAN a platform for collective efforts to advance real-time rendering and computer graphics techniques.

\section{Methods}
\label{sec:methods}


\section{Results and Discussions}
\label{sec:rendering_results}


\section{Conclusions and Future Works}
\label{sec:conclusion}


\begin{acks}


\end{acks}

% Bibliography
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-bibliography}